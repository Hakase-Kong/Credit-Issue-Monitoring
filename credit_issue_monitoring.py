import streamlit as st
import requests
import re
from datetime import datetime
import telepot

# --- ìŠ¤íƒ€ì¼ ê°œì„  ---
st.markdown("""
    <style>
        .block-container {padding-top: 2rem; padding-bottom: 2rem;}
        .stButton button {margin-top: 6px; margin-bottom: 6px; border-radius: 8px;}
        .stTextInput > div > div > input {font-size: 16px;}
        .stMultiSelect [data-baseweb="tag"] {
            background-color: #fff0f0 !important;
            color: #d60000 !important;
            border: 1px solid #d60000 !important;
        }
        .stMultiSelect label { color: #d60000 !important; font-weight: bold;}
        .stSelectbox, .stDateInput, .stMultiSelect {margin-bottom: 0.5rem;}
    </style>
""", unsafe_allow_html=True)

# --- API í‚¤ ì„¤ì • ---
NAVER_CLIENT_ID = "_qXuzaBGk_jQesRRPRvu"
NAVER_CLIENT_SECRET = "lZc2gScgNq"

# --- í…”ë ˆê·¸ë¨ ì„¤ì • ---
TELEGRAM_TOKEN = "7033950842:AAFk4pSb5qtNj435Gf2B5-rPlFrlNqhZFuQ"
TELEGRAM_CHAT_ID = "-1002404027768"

# --- í‚¤ì›Œë“œ ---
credit_keywords = ["ì‹ ìš©ë“±ê¸‰", "ì‹ ìš©í•˜í–¥", "ì‹ ìš©ìƒí–¥", "ë“±ê¸‰ì¡°ì •", "ë¶€ì •ì ", "ê¸ì •ì ", "í‰ê°€"]
finance_keywords = ["ì ì", "í‘ì", "ë¶€ì±„", "ì°¨ì…ê¸ˆ", "í˜„ê¸ˆíë¦„", "ì˜ì—…ì†ì‹¤", "ìˆœì´ìµ", "ë¶€ë„", "íŒŒì‚°"]
all_filter_keywords = sorted(set(credit_keywords + finance_keywords))
default_credit_issue_patterns = [
    "ì‹ ìš©ë“±ê¸‰", "ì‹ ìš©í‰ê°€", "í•˜í–¥", "ìƒí–¥", "ê°•ë“±", "ì¡°ì •", "ë¶€ë„",
    "íŒŒì‚°", "ë””í´íŠ¸", "ì±„ë¬´ë¶ˆì´í–‰", "ì ì", "ì˜ì—…ì†ì‹¤", "í˜„ê¸ˆíë¦„", "ìê¸ˆë‚œ",
    "ì¬ë¬´ìœ„í—˜", "ë¶€ì •ì  ì „ë§", "ê¸ì •ì  ì „ë§", "ê¸°ì—…íšŒìƒ", "ì›Œí¬ì•„ì›ƒ", "êµ¬ì¡°ì¡°ì •", "ìë³¸ì ì‹"
]

# --- ì¦ê²¨ì°¾ê¸° ì¹´í…Œê³ ë¦¬ ---
favorite_categories = {
    "êµ­/ê³µì±„": [],
    "ê³µê³µê¸°ê´€": [],
    "ë³´í—˜ì‚¬": ["í˜„ëŒ€í•´ìƒ", "ë†í˜‘ìƒëª…", "ë©”ë¦¬ì¸ í™”ì¬", "êµë³´ìƒëª…", "ìƒì„±í™”ì¬", "ì‚¼ì„±ìƒëª…", "ì‹ í•œë¼ì´í”„", "í¥êµ­ìƒëª…", "ë™ì–‘ìƒëª…", "ë¯¸ë˜ì—ì…‹ìƒëª…"],
    "5ëŒ€ê¸ˆìœµì§€ì£¼": ["ì‹ í•œê¸ˆìœµ", "í•˜ë‚˜ê¸ˆìœµ", "KBê¸ˆìœµ", "ë†í˜‘ê¸ˆìœµ", "ìš°ë¦¬ê¸ˆìœµ"],
    "5ëŒ€ì‹œì¤‘ì€í–‰": ["ë†í˜‘ì€í–‰", "êµ­ë¯¼ì€í–‰", "ì‹ í•œì€í–‰", "ìš°ë¦¬ì€í–‰", "í•˜ë‚˜ì€í–‰"],
    "ì¹´ë“œì‚¬": ["KBêµ­ë¯¼ì¹´ë“œ", "í˜„ëŒ€ì¹´ë“œ", "ì‹ í•œì¹´ë“œ", "ë¹„ì”¨ì¹´ë“œ", "ì‚¼ì„±ì¹´ë“œ"],
    "ìºí”¼íƒˆ": ["í•œêµ­ìºí”¼íƒˆ", "í˜„ëŒ€ìºí”¼íƒˆ"],
    "ì§€ì£¼ì‚¬": ["SKì´ë…¸ë² ì´ì…˜", "GSì—ë„ˆì§€", "SK", "GS"],
    "ì—ë„ˆì§€": ["SKê°€ìŠ¤", "GSì¹¼í…ìŠ¤", "S-Oil", "SKì—ë„ˆì§€", "SKì•¤ë¬´ë¸Œ", "ì½”ë¦¬ì•„ì—ë„ˆì§€í„°ë¯¸ë„"],
    "ë°œì „": ["GSíŒŒì›Œ", "GSEPS", "ì‚¼ì²œë¦¬"],
    "ìë™ì°¨": ["LGì—ë„ˆì§€ì†”ë£¨ì…˜", "í•œì˜¨ì‹œìŠ¤í…œ", "í¬ìŠ¤ì½”í“¨ì²˜ì— ", "í•œêµ­íƒ€ì´ì–´"],
    "ì „ê¸°/ì „ì": ["SKí•˜ì´ë‹‰ìŠ¤", "LGì´ë…¸í…", "LGì „ì", "LSì¼ë ‰íŠ¸ë¦­"],
    "ì†Œë¹„ì¬": ["ì´ë§ˆíŠ¸", "LF", "CJì œì¼ì œë‹¹", "SKë„¤íŠ¸ì›ìŠ¤", "CJëŒ€í•œí†µìš´"],
    "ë¹„ì² /ì² ê°•": ["í¬ìŠ¤ì½”", "í˜„ëŒ€ì œì² ", "ê³ ë ¤ì•„ì—°"],
    "ì„ìœ í™”í•™": ["LGí™”í•™", "SKì§€ì˜¤ì„¼íŠ¸ë¦­"],
    "ê±´ì„¤": ["í¬ìŠ¤ì½”ì´ì•¤ì”¨"],
    "íŠ¹ìˆ˜ì±„": ["ì£¼íƒë„ì‹œë³´ì¦ê³µì‚¬", "ê¸°ì—…ì€í–‰"]
}

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "favorite_keywords" not in st.session_state:
    st.session_state.favorite_keywords = set()

# --- ì¦ê²¨ì°¾ê¸° ì´ˆê¸° ë“±ë¡ ---
for category_keywords in favorite_categories.values():
    st.session_state.favorite_keywords.update(category_keywords)


# --- ì¦ê²¨ì°¾ê¸° ì¹´í…Œê³ ë¦¬ ì„ íƒ ---
st.markdown("**ì¦ê²¨ì°¾ê¸° ì¹´í…Œê³ ë¦¬ ì„ íƒ**")
selected_categories = st.multiselect("ì¹´í…Œê³ ë¦¬ ì„ íƒ ì‹œ ìë™ìœ¼ë¡œ ì¦ê²¨ì°¾ê¸° í‚¤ì›Œë“œì— ë°˜ì˜ë©ë‹ˆë‹¤.", list(favorite_categories.keys()))
for cat in selected_categories:
    st.session_state.favorite_keywords.update(favorite_categories[cat])


# í•„í„° í•¨ìˆ˜ ìˆ˜ì •

def filter_by_issues(title, desc, selected_keywords, enable_credit_filter, credit_filter_keywords, require_keyword_in_title=False):
    # ì œëª©ì— í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ í™•ì¸ (ì˜µì…˜)
    if require_keyword_in_title and selected_keywords:
        if not any(kw.lower() in title.lower() for kw in selected_keywords):
            return False

    # ì‹ ìš©ì´ìŠˆ í•„í„°
    if enable_credit_filter and not is_credit_risk_news(title + " " + desc, credit_filter_keywords):
        return False

    return True


# fetch_naver_news ìˆ˜ì •

def fetch_naver_news(query, start_date=None, end_date=None, enable_credit_filter=True, credit_filter_keywords=None, limit=100, require_keyword_in_title=False):
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET
    }
    articles = []
    for page in range(1, 6):
        if len(articles) >= limit:
            break
        params = {
            "query": query,
            "display": 10,
            "start": (page - 1) * 10 + 1,
            "sort": "date"
        }
        response = requests.get("https://openapi.naver.com/v1/search/news.json", headers=headers, params=params)
        if response.status_code != 200:
            break
        items = response.json().get("items", [])
        for item in items:
            title, desc = item["title"], item["description"]
            pub_date = datetime.strptime(item["pubDate"], "%a, %d %b %Y %H:%M:%S %z").date()
            if start_date and pub_date < start_date:
                continue
            if end_date and pub_date > end_date:
                continue
            if not filter_by_issues(title, desc, [query], enable_credit_filter, credit_filter_keywords, require_keyword_in_title):
                continue
            articles.append({
                "title": re.sub("<.*?>", "", title),
                "link": item["link"],
                "date": pub_date.strftime("%Y-%m-%d"),
                "source": "Naver"
            })
    return articles[:limit]


# fetch_gnews_news ìˆ˜ì •

def fetch_gnews_news(query, enable_credit_filter=True, credit_filter_keywords=None, limit=100, require_keyword_in_title=False):
    GNEWS_API_KEY = "b8c6d82bbdee9b61d2b9605f44ca8540"
    articles = []
    try:
        url = f"https://gnews.io/api/v4/search"
        params = {
            "q": query,
            "lang": "en",
            "token": GNEWS_API_KEY,
            "max": limit
        }
        response = requests.get(url, params=params)
        if response.status_code != 200:
            st.warning(f"âŒ GNews ìš”ì²­ ì‹¤íŒ¨ - ìƒíƒœ ì½”ë“œ: {response.status_code}")
            return []
        data = response.json()
        for item in data.get("articles", []):
            title = item.get("title", "")
            desc = item.get("description", "")
            if not filter_by_issues(title, desc, [query], enable_credit_filter, credit_filter_keywords, require_keyword_in_title):
                continue
            pub_date = datetime.strptime(item["publishedAt"][:10], "%Y-%m-%d").date()
            articles.append({
                "title": title,
                "link": item.get("url", ""),
                "date": pub_date.strftime("%Y-%m-%d"),
                "source": "GNews"
            })
    except Exception as e:
        st.warning(f"âš ï¸ GNews ì ‘ê·¼ ì˜¤ë¥˜: {e}")
    return articles

def render_articles_columnwise(results, show_limit):
    col_count = min(len(results), 4)
    cols = st.columns(col_count)
    for idx, (keyword, articles) in enumerate(results.items()):
        with cols[idx % col_count]:
            st.markdown(
                f"<span style='font-size:22px;font-weight:700;'>ğŸ“ {keyword}</span>",
                unsafe_allow_html=True
            )
            articles_to_show = articles[:show_limit.get(keyword, 5)]
            for article in articles_to_show:
                st.markdown(
                    f"""
                    <div style='margin-bottom: 12px; padding: 10px; border: 1px solid #eee; border-radius: 10px; background-color: #fafafa;'>
                        <div style='font-weight: bold; font-size: 15px; margin-bottom: 4px;'>
                            <a href="{article['link']}" target="_blank" style='text-decoration: none; color: #1155cc;'>
                                {article['title']}
                            </a>
                        </div>
                        <div style='font-size: 12px; color: gray;'>
                            {article['date']} | {article['source']}
                        </div>
                    </div>
                    """, unsafe_allow_html=True
                )
            if len(articles) > show_limit.get(keyword, 5):
                if st.button("ë”ë³´ê¸°", key=f"more_{keyword}", use_container_width=True):
                    st.session_state.show_limit[keyword] += 5
                    st.rerun()

def send_to_telegram(keyword, articles):
    if articles:
        msg = f"*[{keyword}] ê´€ë ¨ ìƒìœ„ ë‰´ìŠ¤ 5ê±´:*\n"
        for a in articles:
            title = re.sub(r"[\U00010000-\U0010ffff]", "", a['title'])
            msg += f"- [{title}]({a['link']})\n"
        try:
            Telegram().send_message(msg)
        except Exception as e:
            st.warning(f"í…”ë ˆê·¸ë¨ ì „ì†¡ ì˜¤ë¥˜: {e}")

def is_english(text):
    return all(ord(c) < 128 for c in text if c.isalpha())

# process_keywords ìˆ˜ì •

def process_keywords(keyword_list, start_date, end_date, enable_credit_filter, credit_filter_keywords, require_keyword_in_title):
    for k in keyword_list:
        if is_english(k):
            articles = fetch_gnews_news(k, enable_credit_filter, credit_filter_keywords, require_keyword_in_title=require_keyword_in_title)
        else:
            articles = fetch_naver_news(k, start_date, end_date, enable_credit_filter, credit_filter_keywords, require_keyword_in_title=require_keyword_in_title)
        st.session_state.search_results[k] = articles
        st.session_state.show_limit[k] = 5
        send_to_telegram(k, articles[:5])


# --- ìš”ì•½ API í˜¸ì¶œ í•¨ìˆ˜ (ìë™ ì–¸ì–´ ê°ì§€ í¬í•¨ + í…”ë ˆê·¸ë¨ ì „ì†¡ í¬í•¨) ---
def detect_lang_from_title(title):
    return "ko" if re.search(r"[ê°€-í£]", title) else "en"

def summarize_article_from_url(article_url, title):
    try:
        api_url = "https://article-extractor-and-summarizer.p.rapidapi.com/summarize"
        headers = {
            "x-rapidapi-key": "3558ef6abfmshba1bd48265c6fc4p101a63jsnb2c1ee3d33c4",
            "x-rapidapi-host": "article-extractor-and-summarizer.p.rapidapi.com"
        }

        lang = detect_lang_from_title(title)
        params = {
            "url": article_url,
            "lang": lang,
            "engine": "2"
        }

        response = requests.get(api_url, headers=headers, params=params)
        response.raise_for_status()
        result = response.json()

        summary = result.get("summary", "ìš”ì•½ ê²°ê³¼ ì—†ìŒ")
        full_text = result.get("text", "ë³¸ë¬¸ ì—†ìŒ")

        # í…”ë ˆê·¸ë¨ ì „ì†¡
        message = f"*[{title}]*\n{summary}"
        Telegram().send_message(message)

        return summary, full_text

    except Exception as e:
        return f"ìš”ì•½ ì˜¤ë¥˜: {e}", None

# --- ê¸°ì‚¬ í•„í„° ì •í™•ë„ ê°œì„  í•¨ìˆ˜ (ì œëª© + ì„¤ëª… + ìš”ì•½ê¹Œì§€ ì¡°ê±´ ë§Œì¡± ì‹œ ë…¸ì¶œ) ---
def is_relevant_article(title, description, summary, keywords):
    text = f"{title} {description} {summary}"
    return any(kw.lower() in text.lower() for kw in keywords)

# --- ê¸°ì‚¬ ì¹´ë“œ UI ìˆ˜ì •: ìš”ì•½ ë²„íŠ¼ ì¶”ê°€ ---
def render_articles_columnwise_with_summary(results, show_limit):
    col_count = min(len(results), 4)
    cols = st.columns(col_count)
    for idx, (keyword, articles) in enumerate(results.items()):
        with cols[idx % col_count]:
            st.markdown(
                f"<span style='font-size:22px;font-weight:700;'>ğŸ“ {keyword}</span>",
                unsafe_allow_html=True
            )
            articles_to_show = articles[:show_limit.get(keyword, 5)]
            for i, article in enumerate(articles_to_show):
                with st.container():
                    st.markdown(
                        f"""
                        <div style='margin-bottom: 10px; padding: 10px; border: 1px solid #eee; border-radius: 10px; background-color: #fafafa;'>
                            <div style='font-weight: bold; font-size: 15px; margin-bottom: 4px;'>
                                <a href="{article['link']}" target="_blank" style='text-decoration: none; color: #1155cc;'>
                                    {article['title']}
                                </a>
                            </div>
                            <div style='font-size: 12px; color: gray;'>
                                {article['date']} | {article['source']}
                            </div>
                        </div>
                        """,
                        unsafe_allow_html=True
                    )
                    # ìš”ì•½ ë²„íŠ¼
                    if st.button("ìš”ì•½", key=f"summary_{keyword}_{i}", use_container_width=True):
                        with st.spinner("ê¸°ì‚¬ ìš”ì•½ ì¤‘..."):
                            summary, full_text = summarize_article_from_url(article['link'], article['title'])
                            if full_text:
                                st.markdown("<div style='font-size:14px; font-weight:bold;'>ğŸ” ë³¸ë¬¸ ìš”ì•½:</div>", unsafe_allow_html=True)
                                st.write(summary)
                            else:
                                st.warning(summary)

            # ë”ë³´ê¸° ë²„íŠ¼
            if len(articles) > show_limit.get(keyword, 5):
                if st.button("ë”ë³´ê¸°", key=f"more_{keyword}", use_container_width=True):
                    st.session_state.show_limit[keyword] += 5
                    st.rerun()


# --- Streamlit ì„¤ì • ---
st.set_page_config(layout="wide")
st.markdown("<h1 style='color:#1a1a1a; margin-bottom:0.5rem;'>ğŸ“Š Credit Issue Monitoring</h1>", unsafe_allow_html=True)

# --- ê²€ìƒ‰ UI ---
col1, col2, col3 = st.columns([6, 1, 1])
with col1:
    keywords_input = st.text_input("í‚¤ì›Œë“œ (ì˜ˆ: ì‚¼ì„±, í•œí™”)", value="", on_change=lambda: st.session_state.__setitem__('search_triggered', True))
with col2:
    st.write("")
    search_clicked = st.button("ê²€ìƒ‰", use_container_width=True)
with col3:
    st.write("")
    fav_add_clicked = st.button("â­ ì¦ê²¨ì°¾ê¸° ì¶”ê°€", use_container_width=True)
    if fav_add_clicked:
        new_keywords = {kw.strip() for kw in keywords_input.split(",") if kw.strip()}
        st.session_state.favorite_keywords.update(new_keywords)
        st.success("ì¦ê²¨ì°¾ê¸°ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")

# --- ë‚ ì§œ ì…ë ¥ ---
date_col1, date_col2 = st.columns([1, 1])
with date_col1:
    start_date = st.date_input("ì‹œì‘ì¼")
with date_col2:
    end_date = st.date_input("ì¢…ë£Œì¼")

# --- í•„í„° ì˜µì…˜ ---
with st.expander("ğŸ›¡ï¸ ì‹ ìš©ìœ„í—˜ í•„í„° ì˜µì…˜", expanded=True):
    enable_credit_filter = st.checkbox("ì‹ ìš©ìœ„í—˜ ë‰´ìŠ¤ë§Œ í•„í„°ë§", value=False)
    credit_filter_keywords = st.multiselect(
        "ì‹ ìš©ìœ„í—˜ ê´€ë ¨ í‚¤ì›Œë“œ (í•˜ë‚˜ ì´ìƒ ì„ íƒ)",
        options=default_credit_issue_patterns,
        default=default_credit_issue_patterns,
        key="credit_filter"
    )
    
# Streamlit ì¸í„°í˜ì´ìŠ¤ ë‚´ì— ì˜µì…˜ ì¶”ê°€
with st.expander("ğŸ” í‚¤ì›Œë“œ í•„í„° ì˜µì…˜", expanded=True):
    require_keyword_in_title = st.checkbox("ê¸°ì‚¬ ì œëª©ì— í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš°ë§Œ ë³´ê¸°", value=True)

# --- ì¦ê²¨ì°¾ê¸° ê²€ìƒ‰ ---
fav_col1, fav_col2 = st.columns([5, 1])
with fav_col1:
    fav_selected = st.multiselect("â­ ì¦ê²¨ì°¾ê¸°ì—ì„œ ê²€ìƒ‰", sorted(st.session_state.favorite_keywords))
with fav_col2:
    st.write("")
    fav_search_clicked = st.button("ì¦ê²¨ì°¾ê¸°ë¡œ ê²€ìƒ‰", use_container_width=True)


# 5. ê²€ìƒ‰ ë° ì¦ê²¨ì°¾ê¸° ê²€ìƒ‰ ì²˜ë¦¬
search_clicked = False

if keywords_input:
    keyword_list = [k.strip() for k in keywords_input.split(",") if k.strip()]
    if len(keyword_list) > 10:
        st.warning("í‚¤ì›Œë“œëŠ” ìµœëŒ€ 10ê°œê¹Œì§€ ì…ë ¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    else:
        search_clicked = True

if search_clicked or st.session_state.get("search_triggered"):
    keyword_list = [k.strip() for k in keywords_input.split(",") if k.strip()]
    if len(keyword_list) > 10:
        st.warning("í‚¤ì›Œë“œëŠ” ìµœëŒ€ 10ê°œê¹Œì§€ ì…ë ¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    else:
        with st.spinner("ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘..."):
            process_keywords(keyword_list, start_date, end_date, enable_credit_filter, credit_filter_keywords)
    st.session_state.search_triggered = False

if fav_search_clicked and fav_selected:
    with st.spinner("ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘..."):
        process_keywords(fav_selected, start_date, end_date, enable_credit_filter, credit_filter_keywords)

# --- ë‰´ìŠ¤ ê²°ê³¼ í‘œì‹œ ---
if st.session_state.search_results:
    render_articles_columnwise_with_summary(st.session_state.search_results, st.session_state.show_limit)
